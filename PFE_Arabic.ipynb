{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45deae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aeb648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir('arabic_tweets') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "510169a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a91aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58751 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_data = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'arabic_tweets',\n",
    "    # \"inferred\" : the labels are generated from the directory structure\n",
    "    labels = \"inferred\",\n",
    "    # \"int\": the labels are encoded as integers\n",
    "    label_mode = \"int\",\n",
    "    # Maximum size of a text string. Texts longer than this will be shortened \n",
    "    # to max_length unless it's None ra7at explanation f kil zit.\n",
    "    max_length = None,\n",
    "    # Whether to shuffle the data. If False, sorts the data in alphanumeric order.\n",
    "    shuffle=True,\n",
    "    # Finally haja fahmetha mn bkri\n",
    "    seed=11,\n",
    "    # Optional float between 0 and 1, fraction of data to reserve for validation\n",
    "    validation_split=None,\n",
    "    # Only used if validation_split is set, mahich set alors sotit\n",
    "    subset=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "380cb075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes names:\n",
      " ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes names:\\n\",raw_data.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efd5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58751\n",
      "58751\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for text_batch, label_batch in raw_data:\n",
    "    for i in range(len(text_batch)):\n",
    "        s=text_batch.numpy()[i].decode(\"utf-8\") \n",
    "        x.append(s)\n",
    "        y.append(raw_data.class_names[label_batch.numpy()[i]])\n",
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "685e19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data =pd.DataFrame({\"text\":x,\"label\":y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fd0910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58751, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67479aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is null ? :  \n",
      " ****************  text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58751 entries, 0 to 58750\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    58751 non-null  object\n",
      " 1   label   58751 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 918.1+ KB\n",
      "data info : \n",
      " ****************  None\n",
      "is duplicated : \n",
      " *************  21902\n",
      "data shape \n",
      " :  **************  (58751, 2)\n"
     ]
    }
   ],
   "source": [
    "print('is null ? :  \\n **************** ', data.isnull().sum())\n",
    "print('data info : \\n **************** ', data.info())\n",
    "print('is duplicated : \\n ************* ', data.duplicated().sum())\n",
    "print('data shape \\n :  ************** ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd04575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÙŠ ğŸ’° Ù„Ù…ØªØ§Ø¨Ø¹ÙŠ #ÙƒØ´ÙƒÙˆÙ„ ğŸ‘ğŸ» Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>/4/12 - Ø§Ù„Ø§ØªØ­Ø§Ø¯ ÙŠØªÙˆØ¬ Ø¨Ø·Ù„Ø§ Ù„Ù„Ø¯ÙˆØ±ÙŠ. /4/12 - Ø§Ù„Ø§Øª...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ .. ÙƒØ§Ù†Øª Ù…Ø¨Ø§Ø±Ø§Ù‡ ØµØ¹Ø¨Ù‡ ÙˆÙ„ÙƒÙ† Ø¨ØªÙˆÙÙŠÙ‚ Ø§Ù„Ù„Ù‡...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>_â›” #Ù…Ù†Ø§Ø­Ù„_Ø§Ø¨Ùˆ_Ø³Ù„Ø·Ø§Ù† . . ğŸ¯ Ø§Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„Ù‡ Ø§Ù†Ù‡ Ø¹Ø³Ù„ ğŸ¯...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Ø±Ø¦ÙŠØ³ÙŠÙ† ÙÙŠ ÙŠÙˆÙ…ÙŠÙ† Ù‚Ø§Ù„Ùˆ Ø§Ù„Ø±Ø¨ÙŠØ¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ğŸ˜’ Ù†Ø­Ù†Ø§ Ø§Ù„ÙƒØª...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58735</th>\n",
       "      <td>\"ØªÙ„Ø§ØªÙŠÙ† Ø³Ù†Ø© Ø¨ØªØ±Ù‚Øµ .. Ø§Ù„Ù„ÙŠÙ„Ø© Ø±Ù‚ØµØªÙ†Ø§\" Ø£Ù†Ø§ Ø¨Ø¨ÙƒÙŠ ğŸ˜­...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58739</th>\n",
       "      <td>â™¥ï¸ğŸŒ¸ğŸ’ğŸ•Š . ğŸ¥€ Ø£Ø±Ø³Ù„ ØªØ­ÙŠÙ‡ Ø¹Ù„Ù‰ Ù‚Ø¯Ø± Ø§Ù„ØºÙ„Ø§Ø¡ Ø§Ù„ØµØ§ÙÙŠ Ù„Ø£Ø­Ø¨...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58744</th>\n",
       "      <td>Ù²Ù„ÙŠØ³ Ù…Ù† Ø§Ù„Ø¹ÙŠØ¨ Ø§Ù† ØªØ­ÙØ¸ ÙƒÙ„ Ø§Ù„Ø£ØºØ§Ù†ÙŠ .. ÙˆØªÙƒØ±Ø± Ù†ÙØ³ ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58746</th>\n",
       "      <td>Ø£Ù„Ø·Ù Ù…Ø§ Ù‚ÙŠÙ„ ÙÙŠ Ø§Ù„Ø¥Ø´ØªÙŠØ§Ù‚ \"Ù…Ùˆ Ø¶Ø±ÙˆØ±ÙŠ Ø¥Ù†ÙŠ Ø£Ù‚ÙˆÙ„Ùƒ.. ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58749</th>\n",
       "      <td>ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21902 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "66     Ø³Ø­Ø¨ Ø¹Ù„Ù‰ Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÙŠ ğŸ’° Ù„Ù…ØªØ§Ø¨Ø¹ÙŠ #ÙƒØ´ÙƒÙˆÙ„ ğŸ‘ğŸ» Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:...   pos\n",
       "97     /4/12 - Ø§Ù„Ø§ØªØ­Ø§Ø¯ ÙŠØªÙˆØ¬ Ø¨Ø·Ù„Ø§ Ù„Ù„Ø¯ÙˆØ±ÙŠ. /4/12 - Ø§Ù„Ø§Øª...   neg\n",
       "111    Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ .. ÙƒØ§Ù†Øª Ù…Ø¨Ø§Ø±Ø§Ù‡ ØµØ¹Ø¨Ù‡ ÙˆÙ„ÙƒÙ† Ø¨ØªÙˆÙÙŠÙ‚ Ø§Ù„Ù„Ù‡...   pos\n",
       "120    _â›” #Ù…Ù†Ø§Ø­Ù„_Ø§Ø¨Ùˆ_Ø³Ù„Ø·Ø§Ù† . . ğŸ¯ Ø§Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„Ù‡ Ø§Ù†Ù‡ Ø¹Ø³Ù„ ğŸ¯...   neg\n",
       "147    Ø±Ø¦ÙŠØ³ÙŠÙ† ÙÙŠ ÙŠÙˆÙ…ÙŠÙ† Ù‚Ø§Ù„Ùˆ Ø§Ù„Ø±Ø¨ÙŠØ¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ğŸ˜’ Ù†Ø­Ù†Ø§ Ø§Ù„ÙƒØª...   neg\n",
       "...                                                  ...   ...\n",
       "58735  \"ØªÙ„Ø§ØªÙŠÙ† Ø³Ù†Ø© Ø¨ØªØ±Ù‚Øµ .. Ø§Ù„Ù„ÙŠÙ„Ø© Ø±Ù‚ØµØªÙ†Ø§\" Ø£Ù†Ø§ Ø¨Ø¨ÙƒÙŠ ğŸ˜­...   neg\n",
       "58739  â™¥ï¸ğŸŒ¸ğŸ’ğŸ•Š . ğŸ¥€ Ø£Ø±Ø³Ù„ ØªØ­ÙŠÙ‡ Ø¹Ù„Ù‰ Ù‚Ø¯Ø± Ø§Ù„ØºÙ„Ø§Ø¡ Ø§Ù„ØµØ§ÙÙŠ Ù„Ø£Ø­Ø¨...   neg\n",
       "58744  Ù²Ù„ÙŠØ³ Ù…Ù† Ø§Ù„Ø¹ÙŠØ¨ Ø§Ù† ØªØ­ÙØ¸ ÙƒÙ„ Ø§Ù„Ø£ØºØ§Ù†ÙŠ .. ÙˆØªÙƒØ±Ø± Ù†ÙØ³ ...   neg\n",
       "58746  Ø£Ù„Ø·Ù Ù…Ø§ Ù‚ÙŠÙ„ ÙÙŠ Ø§Ù„Ø¥Ø´ØªÙŠØ§Ù‚ \"Ù…Ùˆ Ø¶Ø±ÙˆØ±ÙŠ Ø¥Ù†ÙŠ Ø£Ù‚ÙˆÙ„Ùƒ.. ...   pos\n",
       "58749                   ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n   neg\n",
       "\n",
       "[21902 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5da3442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50898</th>\n",
       "      <td>ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58749</th>\n",
       "      <td>ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text label\n",
       "12279  ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n   neg\n",
       "50898  ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n   neg\n",
       "58749  ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n   neg"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['text']=='ÙˆØ§Ù„Ù„Ù‡ Ø¨Ø§ÙŠÙ†Ù‡ ğŸ˜ğŸ˜ Ù…ÙŠÙ† Ø´Ø±Ù†ÙˆØ¨ÙŠ Ù†Ø§ÙˆğŸ˜‚\\n'] #fu. for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9e8fcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74ff936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36849, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fece737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ù‡ÙØ§ØªÙÙŠÙ’Ù†Ù', 'Ø°ÙŠ', 'Ø¹Ø¬Ø¨Ø§', 'ØºØ§Ø¯Ø±', 'Ù‡Ø§Ù‡Ù†Ø§', 'Ù…Ø§ÙŠ', 'Ø²', 'Ø­Ø§Ø±', 'Ø¢Ù‡', 'Ù…ÙŠÙ…', 'Ø³Ø¨Ø¹ÙˆÙ†', 'Ù…Ø§ Ø§Ù†ÙÙƒ', 'Ù‰', 'Ø¥Ù…Ø§', 'ÙƒØ°Ù„Ùƒ', 'ÙŠÙˆØ±Ùˆ', 'ØªÙÙŠ', 'Ø£Ù', 'Ù‡Ø°Ù‡', 'Ø´Ø±Ø¹', 'Ø®', 'Ø¥Ù†Ù…Ø§', 'Ø£Ù„Ù', 'Ø­Ø§ÙŠ', 'Ø­ÙŠÙÙ‘', 'Ø¡Ù', 'Ø±', 'Ø®Ù„Ø§', 'Ø¹Ù„Ù‚', 'ÙˆØ§Ù‡Ø§Ù‹', 'ÙƒÙŠÙ', 'ØªÙ„Ù‚Ø§Ø¡', 'Ù†Ø¹Ù…', 'Ø¥Ø°Ù…Ø§', 'Ø±Ø§Ø¨Ø¹', 'ØªØ­Øª', 'Ø«Ù…', 'Ø£ÙƒØªÙˆØ¨Ø±', 'Ø£ÙÙÙÙ‘', 'Ø£ÙˆÙ‡', 'Ø£ÙƒØ«Ø±', 'Ø£Ø¨Ùˆ', 'Ø£ÙŠØ¶Ø§', 'Ù†Ø­Ùˆ', 'Ù„Ø¨ÙŠÙƒ', 'Ù„ÙƒÙŠ', 'Ø«Ù…Ø©', 'Ø§Ù†Ø¨Ø±Ù‰', 'Ø¹Ø§Ø´Ø±', 'Ø³ÙŠÙ†', 'Ø´ÙŠÙ†', 'Ø¨ÙƒÙ†', 'ØµØ¯Ù‚Ø§', 'ÙˆÙ‡Ø¨', 'Ø¨Ù…Ø§Ø°Ø§', 'ÙƒØ£ÙŠÙ‘Ù†', 'Ø§Ù„Ù„Ø§ØªÙŠ', 'Ù„Ù†Ø§', 'ÙŠÙˆØ§Ù†', 'Ø³Ø±Ø§', 'Ø¢Ù†Ø§Ø¡', 'Ù„Ùˆ', 'ÙØ¶Ù„Ø§', 'Ø£ÙØ±ÙŠÙ„', 'ÙˆØ§Ùˆ', 'Ø­ÙŠØ«', 'Ø¹Ø¯ÙÙ‘', 'Ø¹ÙØ¯ÙØ³Ù’', 'ØªØ­ÙˆÙ‘Ù„', 'Ù‡Ù†', 'Ø¥ÙŠØ§Ù‡Ù…Ø§', 'Ø«Ù„Ø§Ø«Ø§Ø¡', 'Ø®Ø§ØµØ©', 'ÙˆØ±Ø§Ø¡ÙÙƒ', 'Ø°ÙŠÙ†', 'ÙŠØ§Ø¡', 'Ø¹', 'Ù‡ÙÙŠÙ’Ù‡Ø§Øª', 'Ù†ÙŠØ³Ø§Ù†', 'Ø£ÙˆØ´Ùƒ', 'ÙÙˆÙ‚', 'Ù„ÙŠØª', 'Ù…Ù…Ø§', 'ÙƒØ±Ø¨', 'Ù„Ø§', 'ÙƒÙ†', 'Ø£Ù†Ø§', 'Ø¨Ù‡Ù†', 'Ø£Ø®Ùˆ', 'Ø¢Ù‡Ù', 'Ø¤', 'Ø³Ù‚Ù‰', 'Ù‡Ù„Ù…', 'Ø£Ø±Ø¨Ø¹Ù…Ø¦Ø©', 'Ù„ÙƒÙ†', 'ÙŠÙØ¹Ù„Ø§Ù†', 'Ù„Ù…', 'Ø§Ø«Ù†ÙŠ', 'ØµØ¨Ø§Ø­', 'Ø¥ÙŠØ§Ù‡', 'Ù‡Ø¤Ù„Ø§Ø¡', 'Ø±Ø¬Ø¹', 'Ø«Ù…Ø§Ù†ÙŠØ©', 'Ù…Ù†Ù‡Ø§', 'Ø¥Ø°Ù†', 'Ø¥ÙŠØ§Ù†Ø§', 'Ø®Ù…Ø³Ø©', 'Ù†ÙŠÙ', 'Ø·Ø±Ø§', 'ØªÙ„ÙƒÙ…Ø§', 'Ø®Ø§Ù…Ø³', 'Ù‡ÙŠØª', 'Ù„Ù‡Ù…Ø§', 'Ø¨Ù…Ù†', 'Ù‡Ù…Ø²Ø©', 'Ø§Ø¨ØªØ¯Ø£', 'Ø«Ù…Ù‘', 'Ø¬Ù…Ø¹Ø©', 'Ù…Ø§ÙŠÙˆ', 'Ø®Ø§Ù„', 'Ø´Ù…Ø§Ù„', 'Ø«Ù…ÙÙ‘', 'Ø³Ø§Ø¯Ø³', 'Ø°ÙŠØª', 'Ø¯Ø§Ù„', 'Ø§Ø³ØªØ­Ø§Ù„', 'Ø£Ø±Ø¨Ø¹', 'Ø¬Ø§Ù†ÙÙŠ', 'Ø§Ù„Ø£Ù„Ø§Ø¡', 'Ø´ÙØªÙÙ‘Ø§Ù†Ù', 'Ø¢Ø°Ø§Ø±', 'Ø³Ø¨Ø¹Ù…Ø§Ø¦Ø©', 'ØµØ¨Ø±Ø§', 'Ø«Ù…Ù‘Ø©', 'Ø£Ù…Ø§Ù…Ùƒ', 'Ø³Ø±Ø¹Ø§Ù†', 'Ø£ÙŠÙ†Ù…Ø§', 'Ù…Ø§ÙØªØ¦', 'Ø¥ÙŠØ§Ù‡Ù…', 'Ø°Ù„ÙƒÙ…', 'ØµØ¨Ø±', 'ØªØ¹Ù„ÙÙ‘Ù…', 'Ø¬', 'ÙŠÙˆÙ„ÙŠÙˆ', 'Ø¹Ù„Ù‰', 'Ø·', 'Ù‚Ø¨Ù„', 'ÙˆÙ…Ù†', 'Ù…ØªÙ‰', 'ÙˆØ¥Ù†', 'Ø¥Ù„Ù‘Ø§', 'Ø®Ù…Ø³', 'Ù‡Ø°ÙŠÙ†', 'Ø¯ÙŠÙ†Ø§Ø±', 'Ø³ØªÙŠÙ†', 'Ø¹ÙŠØ§Ù†Ø§', 'Ù„Ùƒ', 'ÙƒÙ„ÙŠÙƒÙ…Ø§', 'Ù‡ÙŠÙ‘Ø§', 'Ø¢', 'Ù‡', 'ØªØ§Ø±Ø©', 'Ø¨ØºØªØ©', 'Ø£ÙˆÙ‘Ù‡Ù’', 'ØªÙØ¹Ù„ÙŠÙ†', 'ÙˆØ¥Ø°', 'Ù‡ÙØ§ØªÙÙŠ', 'Ù‡Ø¨Ù‘', 'Ø·Ø§Ø¡', 'ØµÙ‡Ù', 'ØªØ§Ø¡', 'Ø´ØªØ§Ù†Ù', 'Ù„Ù‡Ø§', 'Ø¨Ø®', 'Ø¹ÙˆØ¶', 'Ø¢Ø¶', 'ØªØ§Ù†Ù', 'Ø£Ø¹Ù„Ù…', 'ÙƒØ£Ù†Ù…Ø§', 'ÙŠÙ†', 'Ù…Ø§ Ø¨Ø±Ø­', 'Ø³', 'Ù‡ÙØ°ÙÙŠÙ’Ù†Ù', 'Ø¨Ø¹Ø¯', 'Ø£Ø³ÙƒÙ†', 'Ø³Ø§Ø¡', 'Ø£ØµÙ„Ø§', 'Ø¥ÙŠØ§Ùƒ', 'Ø­Ù…ÙŒ', 'Ù„ÙŠØ±Ø©', 'Ø¬ÙŠØ±', 'Ù‡Ø§', 'ÙÙŠÙØ±ÙŠ', 'ØªÙ„Ùƒ', 'Ø¨ÙØ³Ù’', 'ÙƒÙ„Ø§Ù‡Ù…Ø§', 'Ø¨Ø³', 'Ø£Ù‚Ø¨Ù„', 'Ø³ÙˆÙ‰', 'Ø£ÙˆÙ„Ø¦Ùƒ', 'Ø£Ø±Ø¨Ø¹Ø©', 'Ø¬Ù„Ù„', 'Ø§Ù†Ù‚Ù„Ø¨', 'Ø£Ù‚Ù„', 'ÙƒÙ…Ø§', 'Ø°Ù„ÙƒÙ…Ø§', 'ÙŠØ§', 'Ø£Ù†Øª', 'ØªØ³Ø¹Ù…Ø¦Ø©', 'Ø¹Ù„Ù‹Ù‘', 'Ø§', 'ÙØ±Ø§Ø¯Ù‰', 'Ø£ÙŠÙ‘Ø§Ù†', 'ÙÙ„Ø§', 'Ø¹Ø¯Ø§', 'Ù‡ÙŠÙ‡Ø§Øª', 'ØªØ±Ùƒ', 'Ø¨ÙŠØ¯', 'Ø§Ø±Ø¨Ø¹ÙˆÙ†', 'ÙÙŠÙ‡', 'ÙˆÙÙŠÙ’', 'Ø®Ù…Ø³ÙŠÙ†', 'Ù…Ù†Ø°', 'Ø¥ÙŠØ§ÙƒÙ†', 'Ø£Ù…Ø§Ù…', 'Ø·Ø§Ù„Ù…Ø§', 'ÙŠÙˆÙ†ÙŠÙˆ', 'Ø¥Ø°Ø§Ù‹', 'Ø¨ÙƒÙ…', 'Ø§Ù„Ù„Ø°ÙŠÙ†', 'Ø­Ø¨ÙŠØ¨', 'Ø£Ù†ØªÙ…', 'Ø£Ø±Ø¨Ø¹Ù…Ø§Ø¦Ø©', 'Ø£Ø¬Ù…Ø¹', 'Ø®Ù…Ø³ÙˆÙ†', 'Ø¬Ø¹Ù„', 'Ù„ÙƒÙ†Ù…Ø§', 'Ø¥Ù†ÙÙ‘', 'Ø§Ù„Ù„ÙˆØ§ØªÙŠ', 'Ø£Ù‡Ù„Ø§', 'Ø¨ÙŠÙ†', 'Ø­ØªÙ‰', 'Ø¨Ø¶Ø¹', 'Ù†ÙØ®Ù’', 'Ù†ÙˆÙ†', 'ØºØ¯Ø§', 'Ø°Ù„Ùƒ', 'Ø±ÙŠØ«', 'Ø£ÙŠÙ‡Ø§', 'Ù‡Ø§ÙƒÙ', 'Ø¥Ø°Ø§', 'Ø£Ù…', 'Ø¨', 'Ù…', 'Ø£Ø®ÙŒ', 'Ø¹ÙŠÙ†', 'Ø¨Ù‡Ø§', 'Ø¥Ù„ÙÙŠÙ’ÙƒÙ', 'Ø£Ù…Ø§', 'Ø§Ù„Ù„ØªØ§Ù†', 'Ø°ÙÙ‡', 'Ù‚Ù„Ù…Ø§', 'Ø°ÙÙŠ', 'Ø¥Ù†', 'Ø¹Ø³Ù‰', 'Ø°Ù‡Ø¨', 'Ù‡ÙŠ', 'Ø£Ø¨ÙŒ', 'Ø°Ø§Ùƒ', 'Ø³ÙˆÙ', 'ÙŠÙØ¹Ù„ÙˆÙ†', 'Ø²Ø¹Ù…', 'Ø£Ùˆ', 'Ø¢Ù‡Ù', 'Ø±ÙØ¨ÙÙ‘', 'Ø¥ÙŠ', 'Ø¶Ø­ÙˆØ©', 'Ø³Ø¨Øª', 'ÙˆØ§Ø­Ø¯', 'Ø¥Ù…Ù‘Ø§', 'Ø«Ù„Ø§Ø«Ù…Ø§Ø¦Ø©', 'Ø«Ù…Ø§Ù†ÙŠÙ†', 'Ø£ÙˆÙ„Ø§Ù„Ùƒ', 'ØºØ¯Ø§Ø©', 'Ø£Ø¬Ù„', 'Ø£Ù„Ø§', 'ÙˆÙ„Ùˆ', 'Ø¨Ùƒ', 'ÙƒÙ„', 'Ù‡ÙØ°Ø§Ù†Ù', 'Ø³ØªØ©', 'Ø¹Ù„ÙŠÙƒ', 'Ø§Ø«Ù†ÙŠÙ†', 'ÙƒØ§Ø¯', 'Ø£ÙØ¹Ù„ Ø¨Ù‡', 'Ø¥Ù„ÙŠÙƒÙ…', 'Ù‡ÙƒØ°Ø§', 'Ø±Ø§Ø­', 'Ù„Ø¹Ù„', 'Ù…Ø³Ø§Ø¡', 'Ù…Ø¦ØªØ§Ù†', 'ØºØ§Ù„Ø¨Ø§', 'Ø´ØªØ§Ù†', 'Ø¥Ø²Ø§Ø¡', 'Ø£Ø±Ø¨Ø¹Ø§Ø¡', 'Ø¯ÙˆØ§Ù„ÙŠÙƒ', 'ØªÙŠ', 'Ù†', 'Ø¹Ù„', 'Ø£Ø·Ø¹Ù…', 'Ø´', 'Ù„ÙŠØ³Øª', 'Ø¬Ù†ÙŠÙ‡', 'Ø¢ÙŠ', 'Ø­Ø³Ø¨', 'Ø°Ù„ÙƒÙ†', 'ÙƒØ£ÙŠÙ†', 'Ø£', 'ÙˆØ¥Ø°Ø§', 'Ù‡Ù„Ù„Ø©', 'ÙØ§Ø¡', 'Ø§Ø«Ù†Ø§', 'Ù„Ø³Ù†Ø§', 'Ø¹Ù†', 'Ø§Ù„Ø£Ù„Ù‰', 'Ø°ÙˆØ§ØªØ§', 'Ù‘Ø£ÙŠÙ‘Ø§Ù†', 'Ø«Ù„Ø§Ø«ÙŠÙ†', 'Ø·ÙÙ‚', 'ÙƒØ§Ù', 'Ø³Ø­Ù‚Ø§', 'Ø£ÙˆØª', 'Ø´Ø¨Ø§Ø·', 'Ø¥ÙŠÙ‡Ù', 'Ù„ÙŠØ³Ø§', 'Ù‡Ù†Ø§Ùƒ', 'Ù„Ø¯Ù‰', 'Ø­Ø¯ÙØ«', 'Ø­Ø±Ù‰', 'Ø·Ø§Ù‚', 'ÙƒÙ„Ù…Ø§', 'Ø£ØºØ³Ø·Ø³', 'ØªØ¬Ø§Ù‡', 'Ù„Ø¦Ù†', 'ÙØ¨Ø±Ø§ÙŠØ±', 'ØªÙŠÙ†Ùƒ', 'Ù„Ù†', 'Ø¨ÙÙ„Ù’Ù‡Ù', 'Ù†Ø¨ÙÙ‘Ø§', 'ÙØ¥Ù†', 'Ø£Ù†ØªÙ…Ø§', 'Ø£Ø­Ø¯', 'Ù„Ù…Ø§', 'Ø§Ø±Ø¨Ø¹ÙŠÙ†', 'Ø®Ù„Ù', 'Ø°Ùˆ', 'Ø«Ù„Ø§Ø«Ù…Ø¦Ø©', 'ØªØ³Ø¹', 'Ù‡Ù†Ø§', 'Ø±ÙŠØ§Ù„', 'Ù‡Ø°Ø§Ù†', 'Ù‡Ø§Ø¡', 'Ø°Ø§Ù„', 'Ø¹Ø§Ù…Ø©', 'Ø£ÙŠÙ‘', 'Ø¹Ù„ÙŠÙ‡', 'Ù‡ÙØ§ØªØ§Ù†Ù', 'Ø±Ø§Ø¡', 'Ø£Ø®Ø¨Ø±', 'Ø¥Ù‰', 'Ù‡ÙØ°Ø§', 'ØµØ§Ø¯', 'Ø§Ù„Ø°ÙŠÙ†', 'Ù„ÙƒÙŠÙ„Ø§', 'Ø£Ù…Ø³Ù‰', 'Ø¬Ù…ÙŠØ¹', 'ÙˆØ¬Ø¯', 'ØªØ³Ø¹Ù…Ø§Ø¦Ø©', 'ÙÙŠÙ…', 'ÙƒÙ„Ù‘Ù…Ø§', 'Ø§Ù„Ù„ØªÙŠÙ†', 'ÙƒØ£ÙŠÙ‘', 'Ø³Ø¨Ø¹Ù…Ø¦Ø©', 'Ù…Ø§Ø²Ø§Ù„', 'Ø£ÙŠ', 'ÙƒØ³Ø§', 'Ø´Ø¨Ù‡', 'Ø£ÙÙÙ‘', 'ÙˆÙ…Ø§', 'Ø©', 'Ù…Ù„ÙŠÙ…', 'ÙÙ„Ø³', 'Ù…Ù†Ù‡', 'Ø±Ø£Ù‰', 'Ø¢Ù†ÙØ§', 'Ù„Ø¹Ù„ÙÙ‘', 'Ø­ÙŠØ«Ù…Ø§', 'Ø®Ù…Ø³Ù…Ø§Ø¦Ø©', 'ÙÙˆ', 'Ù‡Ù†Ø§Ù„Ùƒ', 'Ø«Ù…Ø§Ù†', 'Ø¨Ø§Ø¡', 'Ø£Ù…Ø¯', 'Ø¹Ø´Ø±ÙˆÙ†', 'Ù…Ù†', 'ÙƒØ°Ø§', 'Ø«Ø§Ù†ÙŠ', 'Ø£ÙŠÙ†', 'Ø¨ÙŠ', 'Ù„ÙˆÙ„Ø§', 'ØªØ¨Ø¯Ù‘Ù„', 'Ø°ÙˆØ§', 'Ù„ÙƒÙ…', 'ÙƒØ§Ù†', 'ÙƒÙŠÙÙ…Ø§', 'ØºÙŠÙ†', 'Ù‡ÙŠØ§', 'Ø¸Ø§Ø¡', 'ØªØ§Ø³Ø¹', 'Ø³Ø¨Ø­Ø§Ù†', 'Ø¨Ø·Ø¢Ù†', 'Ø°ÙŠÙ†Ùƒ', 'Ø­Ù…Ùˆ', 'Ù„ÙŠØ³ØªØ§', 'ÙˆÙØ´Ù’ÙƒÙØ§Ù†Ù', 'Øµ', 'Ø·ÙÙ‚', 'Ø²ÙˆØ¯', 'Ø£Ù„ÙÙ‰', 'Ø¸Ù†ÙÙ‘', 'Ø¨Ø³Ù‘', 'Ù…Ø°', 'Ø¨Ø¹Ø¶', 'Ø¥ÙŠØ§ÙƒÙ…Ø§', 'Ø¶Ø§Ø¯', 'Ø¨Ù‡Ù…', 'Ø°Ø§', 'Ø°ÙÙŠÙ’Ù†Ù', 'Ø¢Ù‡Ø§Ù‹', 'Ù„Ø³Øª', 'Ø«Ù…Ø§Ù†Ù…Ø¦Ø©', 'Ø«Ø§Ù†', 'Ø°Ù‡', 'Ù‡Ø§ØªØ§Ù†', 'Ù‡Ø°Ø§', 'Ù‡Ø°ÙŠ', 'Ø­Ù‚Ø§', 'Ù„Ø³ØªÙ†', 'Ø³Ù…Ø¹Ø§', 'ÙˆÙ„ÙƒÙ†', 'Ù‚Ø±Ø´', 'Ø£Ø±Ù‰', 'Ø¯Ø±Ù‰', 'ÙƒÙ„ÙÙ‘Ø§', 'Ø¥Ù„ÙŠÙƒÙ†Ù‘', 'ÙÙ…Ù†', 'Ø¡', 'ØªÙ‡', 'ØªÙŠÙ†', 'ØªÙÙ‡', 'Ù…Ø§', 'Ø£ÙˆÙ„Ø§Ø¡', 'Ø°Ø§Ù†Ùƒ', 'Ø­ÙØ°Ø§Ø±Ù', 'Ø¬ÙˆØ§Ù†', 'Ø«Ù„Ø§Ø«', 'Ø¥Ø°', 'Ù', 'Ø£Ù†ØªÙ†', 'Ù†ÙˆÙÙ…Ø¨Ø±', 'ØªÙÙŠÙ’Ù†Ù', 'Ø«Ø§Ù„Ø«', 'ÙƒÙ„ØªØ§', 'Ø«Ù„Ø§Ø«ÙˆÙ†', 'ØªØ³Ø¹ÙŠÙ†', 'Ø°Ø§Øª', 'ÙƒØ§Ù†ÙˆÙ†', 'Ø´ÙŠÙƒÙ„', 'Ø³Ø¨ØªÙ…Ø¨Ø±', 'Ø§Ø®Ù„ÙˆÙ„Ù‚', 'ÙŠÙ†Ø§ÙŠØ±', 'ÙƒÙØ®', 'ØªØ®Ø°', 'ØµØ±Ø§Ø­Ø©', 'Ù…Ø§Ø¯Ø§Ù…', 'Ù„Ù…Ù‘Ø§', 'Ø£Ø¹Ø·Ù‰', 'Ù„Ø³ØªÙ…', 'Ø¥Ù„ÙŠÙƒÙ…Ø§', 'ØªÙ…ÙˆØ²', 'Ø£Ù†ØªÙ', 'Ù„ÙˆÙ…Ø§', 'Ù‚Ø§Ù', 'Ø¨Ù…Ø§', 'ÙƒØ£Ù†Ù‘', 'Ø«', 'Ø¥Ù„ÙŠÙƒ', 'ØªØ¹Ø³Ø§', 'Ø¥Ù„ÙŠÙƒÙ†', 'Ø­Ø§Ø´Ø§', 'Ø®Ø¨ÙÙ‘Ø±', 'Ø£Ù†Ø¨Ø£', 'Ø³Øª', 'Ø«Ø§Ù…Ù†', 'Ø¶', 'Ø¹Ù†Ø¯', 'Ø£Ù…Ù‘Ø§', 'Ù‡Ù…Ø§', 'Ø£Ù…Ø³', 'Ø®Ù„Ø§ÙØ§', 'ÙƒÙ…', 'Ø¥Ø­Ø¯Ù‰', 'Ø¨Ù„', 'Ø«Ø§Ø¡', 'ÙÙŠ', 'Ø­Ø§Ø¯ÙŠ', 'Ù†ÙØ³', 'Ù‡Ø§ØªÙ‡', 'Ø¥Ù†Ø§', 'Ø¸', 'Ù…Ø§ Ø£ÙØ¹Ù„Ù‡', 'Ø³Ø¨Ø¹ÙŠÙ†', 'Ø³Ø§Ø¨Ø¹', 'Ø«Ù…Ø§Ù†ÙŠ', 'ØµÙ‡Ù’', 'ÙˆØ§', 'Ø³ØªÙ…Ø¦Ø©', 'Ø¥ÙŠØ§ÙƒÙ…', 'Ø¯ÙˆÙ†', 'Ø§Ù„Ù„Ø§Ø¦ÙŠ', 'Ø±Ø²Ù‚', 'Ù‡ÙØ°ÙÙŠ', 'Ø±ÙˆÙŠØ¯Ùƒ', 'Ù‡ÙØ¬Ù’', 'Ø§Ù„Ø°ÙŠ', 'Ø¹Ø´Ø±ÙŠÙ†', 'Ù‚', 'Ø¨Ø¤Ø³Ø§', 'Ø¨Ù†Ø§', 'Ø¹Ù…Ø§', 'ØªÙØ¹Ù„ÙˆÙ†', 'Ø§Ø±ØªØ¯Ù‘', 'ØªØ³Ø¹Ø©', 'Ù†Ø§', 'Ù„Ù‡Ù…', 'Ù„', 'Ù…Ù‡', 'ÙƒÙŠØª', 'Ù‡Ù…', 'Ø¯', 'Ùƒ', 'Ù…Ø¹Ø§Ø°', 'Ù„ÙŠØ³', 'Ù…ÙƒØ§Ù†ÙƒÙ…', 'Ø£Ø®Ø°', 'Ø­Ù…Ø¯Ø§', 'Ù„Ø¹Ù…Ø±', 'Ø­Ø¨Ø°Ø§', 'Ø¸Ù„Ù‘', 'Ù„Ø§Ø³ÙŠÙ…Ø§', 'Ø¹Ø§Ø¯', 'Ù‡Ù„', 'Ø£ÙŠÙ„ÙˆÙ„', 'Øª', 'Ù†ÙÙ‘', 'Ø¹Ø´Ø±', 'ØªØ§Ù†ÙÙƒ', 'Ø°ÙˆØ§ØªÙŠ', 'ØªÙØ¹Ù„Ø§Ù†', 'Ø£Ø¨Ø¯Ø§', 'Ø®Ø§Ø¡', 'Ø¨Ø§Øª', 'Ø§Ù„Ù„Ø°Ø§Ù†', 'Ø³Ø¨Ø¹', 'Ø§ØªØ®Ø°', 'Ø­Ø§Ø¡', 'Ù…Ø§Ø¦Ø©', 'Ø«Ù…Ù†Ù…Ø¦Ø©', 'Ù‡Ù„Ø§', 'Ø«Ù…Ø§Ù†ÙˆÙ†', 'ÙƒØ«ÙŠØ±Ø§', 'Ù‚Ø·Ù‘', 'Ø¨Ù‡', 'Ø£ÙˆÙ„', 'Ù…Ø¹', 'Ø¥ÙŠØ§Ù‡Ù†', 'Ø¨Ø¹Ø¯Ø§', 'Ø£ÙŠØ§', 'Ù„ÙƒÙ†ÙÙ‘', 'Ø¹Ù„Ù…', 'Ø¬ÙˆÙŠÙ„ÙŠØ©', 'ÙˆØ§Ù„Ø°ÙŠÙ†', 'Ù„ÙƒÙ…Ø§', 'Ø¥Ù„Ø§', 'Ø¨Ù„Ù‰', 'Ø­Ø²ÙŠØ±Ø§Ù†', 'Ù…Ø§Ø±Ø³', 'Ø§Ø«Ù†Ø§Ù†', 'Ù…ÙƒØ§Ù†ÙƒÙ…Ø§', 'ÙƒÙ„ÙŠÙ‡Ù…Ø§', 'Ø¬ÙŠÙ…', 'Ù‡ÙØ§ØªÙÙ‡', 'Ø²Ø§ÙŠ', 'Ø¥Ù†Ù‡', 'ÙˆÙ‡Ùˆ', 'Ø³ØªÙ…Ø§Ø¦Ø©', 'Ø¥Ù„Ù‰', 'Ù…Ø«Ù„', 'Ø¥Ù„ÙŠÙƒÙ', 'Ø£Ù†Ù‰', 'ÙÙŠÙ‡Ø§', 'Ø¯ÙˆÙ†Ùƒ', 'Ø³Ø¨Ø¹Ø©', 'ØªÙ„ÙƒÙ…', 'Øº', 'Ù‚Ø¯', 'Ù„ÙŠØ³ÙˆØ§', 'Ø¢Ù…ÙŠÙ†Ù', 'Ø£Ø¨Ø±ÙŠÙ„', 'Ùˆ', 'Ù‡ÙØ¤Ù„Ø§Ø¡', 'Ø®Ù…ÙŠØ³', 'Ù…Ù‡Ù…Ø§', 'ÙƒÙ„Ø§', 'ÙØ¥Ø°Ø§', 'Ø­', 'Ø¨ÙƒÙ…Ø§', 'Ù…ÙƒØ§Ù†ÙƒÙ†Ù‘', 'Ø£ØµØ¨Ø­', 'Ø£Ù†Ù‹Ù‘', 'Ø£Ø¶Ø­Ù‰', 'Ù‚Ø§Ù…', 'ÙƒÙŠ', 'Ø§Ù„Ù„ØªÙŠØ§', 'Ù…ÙƒØ§Ù†ÙÙƒ', 'Ø°Ø§Ù†', 'Ø®Ù…Ø³Ù…Ø¦Ø©', 'Ø£Ù‰', 'Ù„Ø§ Ø³ÙŠÙ…Ø§', 'ØªØ³Ø¹ÙˆÙ†', 'Ø¯Ø±Ù‡Ù…', 'Ø¨Ù‡Ù…Ø§', 'ØºÙŠØ±', 'Ù„Ù‡', 'Ù‡Ù„Ù‘Ø§', 'Ø¦', 'Ù‡Ùˆ', 'Ø¢Ù‡Ø§', 'ÙƒØ£Ù†', 'Ù„Ø§Ù…', 'Ù„ÙŠ', 'Ø¯ÙŠØ³Ù…Ø¨Ø±', 'Ø¨Ø®Ù', 'Ù„Ø¯Ù†', 'Ù‡Ø§Ùƒ', 'Ø¢Ø¨', 'ØªØ´Ø±ÙŠÙ†', 'Ø­Ø¬Ø§', 'ÙÙ„Ø§Ù†', 'Ù‡Ø§ØªÙŠ', 'Ø¯ÙˆÙ„Ø§Ø±', 'Ø£Ù†', 'ØµØ§Ø±', 'ÙŠ', 'Ù…Ø§Ø°Ø§', 'Ù„Ù‡Ù†', 'Ù„Ø³ØªÙ…Ø§', 'Ù…Ù…Ù†', 'Ø£ÙŠØ§Ø±', 'Ø£Ù†Ù‘Ù‰', 'Ø°', 'Ø¥ÙŠÙ‡', 'ÙÙŠÙ…Ø§', 'Ø¥ÙŠØ§Ù‡Ø§', 'Ø¥ÙŠØ§ÙŠ', 'Ø§Ù„ØªÙŠ', 'ÙƒÙ‰', 'Ø³ØªÙˆÙ†', 'Ø³Ù†ØªÙŠÙ…', 'ÙˆØ±Ø¯', 'Ø£Ù„', 'Ù‡Ø§ØªÙŠÙ†', 'Ø°Ø§Ù†Ù', 'Ø¹Ø´Ø±Ø©', 'Ø«Ù„Ø§Ø«Ø©', 'ÙƒØ£ÙŠ', 'Ù„Ø§Øª', 'ÙˆÙ„Ø§', 'Ø­ÙŠÙ†', 'Ù…Ø¦Ø©', 'Ù„Ø³Ù†', 'Ø§Ù„Ø¢Ù†', 'ÙŠÙ…ÙŠÙ†', 'Ø£Ù…Ø§Ù…ÙƒÙ', 'Ù‚Ø§Ø·Ø¨Ø©', 'ÙˆØ§Ù„Ø°ÙŠ', 'Ù…Ø±Ù‘Ø©', 'Ù†Ø­Ù†', 'Ù‡ÙØ°ÙÙ‡', 'Ø¨Ø¦Ø³', 'Ø£Ù†Ø´Ø£']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ethernet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = list(set(stopwords.words('arabic')))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a77ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "arabic_punctuations = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f586265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"\"\" Ù‘    | # Tashdid\n",
    "                             Ù    | # Fatha\n",
    "                             Ù‹    | # Tanwin Fath\n",
    "                             Ù    | # Damma\n",
    "                             ÙŒ    | # Tanwin Damm\n",
    "                             Ù    | # Kasra\n",
    "                             Ù    | # Tanwin Kasr\n",
    "                             Ù’    | # Sukun\n",
    "                             Ù€     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(arabic_diacritics, '', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_diacritics(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word for word in tokens if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d89ed662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.. Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ : ğŸŒ¿ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ğŸŒ±...</td>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ÙˆØ£Ø¨ØªØ³Ø§Ù…Ú¾...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ ğŸ’› #Ø§Ù„Ø§ØªØ­Ø§Ø¯_Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·...</td>\n",
       "      <td>pos</td>\n",
       "      <td>Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ Ø§Ù„Ø§ØªØ­Ø§Ø¯Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·ÙˆØ§Ù‚ÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù„Ø§ ØªØ¹Ù„Ù… Ø£ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„ØªÙŠ Ø³ØªÙ‚Ø± Ø¨Ù‡Ø§ Ø¹ÙŠÙ†Ùƒ ÙÙŠ Ø¯Ù†ÙŠØ§Ùƒ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>ØªØ¹Ù„Ù… Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø³ØªÙ‚Ø± Ø¹ÙŠÙ†Ùƒ Ø¯Ù†ÙŠØ§Ùƒ ÙˆØ£Ø®Ø±Ø§ÙƒØŒ ØªØ­ÙŠÙ„ Ù‚Ø§Ø¨Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ğŸ’› ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯...</td>\n",
       "      <td>pos</td>\n",
       "      <td>Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯ Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± // ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ :(\\n</td>\n",
       "      <td>neg</td>\n",
       "      <td>Ø§Ù„Ø®ÙŠØ± ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  .. Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ : ğŸŒ¿ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ğŸŒ±...   pos   \n",
       "1  Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ ğŸ’› #Ø§Ù„Ø§ØªØ­Ø§Ø¯_Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·...   pos   \n",
       "2  Ù„Ø§ ØªØ¹Ù„Ù… Ø£ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„ØªÙŠ Ø³ØªÙ‚Ø± Ø¨Ù‡Ø§ Ø¹ÙŠÙ†Ùƒ ÙÙŠ Ø¯Ù†ÙŠØ§Ùƒ...   pos   \n",
       "3  Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ğŸ’› ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯...   pos   \n",
       "4              ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± // ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ :(\\n   neg   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ÙˆØ£Ø¨ØªØ³Ø§Ù…Ú¾...  \n",
       "1  Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ Ø§Ù„Ø§ØªØ­Ø§Ø¯Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·ÙˆØ§Ù‚ÙŠ...  \n",
       "2  ØªØ¹Ù„Ù… Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø³ØªÙ‚Ø± Ø¹ÙŠÙ†Ùƒ Ø¯Ù†ÙŠØ§Ùƒ ÙˆØ£Ø®Ø±Ø§ÙƒØŒ ØªØ­ÙŠÙ„ Ù‚Ø§Ø¨Ù„...  \n",
       "3  Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯ Ø§...  \n",
       "4                           Ø§Ù„Ø®ÙŠØ± ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b538712a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.. Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ : ğŸŒ¿ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ğŸŒ±...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ÙˆØ£Ø¨ØªØ³Ø§Ù…Ú¾...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ ğŸ’› #Ø§Ù„Ø§ØªØ­Ø§Ø¯_Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ Ø§Ù„Ø§ØªØ­Ø§Ø¯Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·ÙˆØ§Ù‚ÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù„Ø§ ØªØ¹Ù„Ù… Ø£ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„ØªÙŠ Ø³ØªÙ‚Ø± Ø¨Ù‡Ø§ Ø¹ÙŠÙ†Ùƒ ÙÙŠ Ø¯Ù†ÙŠØ§Ùƒ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ØªØ¹Ù„Ù… Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø³ØªÙ‚Ø± Ø¹ÙŠÙ†Ùƒ Ø¯Ù†ÙŠØ§Ùƒ ÙˆØ£Ø®Ø±Ø§ÙƒØŒ ØªØ­ÙŠÙ„ Ù‚Ø§Ø¨Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ğŸ’› ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯ Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± // ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ :(\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ø®ÙŠØ± ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  .. Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ : ğŸŒ¿ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ğŸŒ±...      1   \n",
       "1  Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ ğŸ’› #Ø§Ù„Ø§ØªØ­Ø§Ø¯_Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·...      1   \n",
       "2  Ù„Ø§ ØªØ¹Ù„Ù… Ø£ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø§Ù„ØªÙŠ Ø³ØªÙ‚Ø± Ø¨Ù‡Ø§ Ø¹ÙŠÙ†Ùƒ ÙÙŠ Ø¯Ù†ÙŠØ§Ùƒ...      1   \n",
       "3  Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ğŸ’› ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯...      1   \n",
       "4              ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± // ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ :(\\n      0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Ø§Ù…Ù†ÙŠÚ¾ Ù…Ø³Ø§Ø¦ÙŠÚ¾ Ø±Ø¨ÙŠ Ø£ÙƒØªØ¨ Ù„Ù†Ø¢ Ø³Ø¹Ø§Ø¯Ú¾ Ø¯Ø§Ø¦Ù…Ú¾ ÙˆØ£Ø¨ØªØ³Ø§Ù…Ú¾...  \n",
       "1  Ø§Ù„Ù†ØµØ± Ù„Ù„Ù†ØµØ± Ø¨Ø§Ø°Ù† Ø§Ù„Ù„Ù‡ Ø§Ù„Ø§ØªØ­Ø§Ø¯Ø§Ù„Ù†ØµØ± Ø­Ø§Ù„ Ø§Ù„Ø·ÙˆØ§Ù‚ÙŠ...  \n",
       "2  ØªØ¹Ù„Ù… Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø³ØªÙ‚Ø± Ø¹ÙŠÙ†Ùƒ Ø¯Ù†ÙŠØ§Ùƒ ÙˆØ£Ø®Ø±Ø§ÙƒØŒ ØªØ­ÙŠÙ„ Ù‚Ø§Ø¨Ù„...  \n",
       "3  Ø¨Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡ ÙÙˆØ² ÙŠØ³Ø± Ù‚Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø§Ø´Ù‚ÙŠÙŠÙ† ÙˆÙŠØºÙŠØ¶ ÙƒØ¨ÙˆÙˆØ¯ Ø§...  \n",
       "4                           Ø§Ù„Ø®ÙŠØ± ÙˆØ§Ù‚ØµØ¯ Ø¨Ø§Ù„Ø®ÙŠØ± Ø­Ø¨ÙŠØ¨ÙŠ  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert positive 1 and negative 0\n",
    "data['label']=data['label'].apply(lambda X: 0 if X == 'neg' else 1 )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d39ead40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from time import time \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Activation,Embedding,Flatten,Bidirectional,MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import h5py\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89ceaac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Length: 29479\n",
      "Testing Set Length: 7370\n",
      "training_sentences shape: (29479,)\n",
      "testing_sentences shape: (7370,)\n",
      "train_labels shape: (29479, 2)\n",
      "test_labels shape: (7370, 2)\n"
     ]
    }
   ],
   "source": [
    "train1, test1 = train_test_split(data,random_state=69, test_size=0.2)\n",
    "training_sentences = []\n",
    "testing_sentences = []\n",
    "\n",
    "\n",
    "\n",
    "train_sentences=train1['cleaned_text'].values\n",
    "train_labels=train1['label'].values\n",
    "for i in range(train_sentences.shape[0]): \n",
    "    #print(train_sentences[i])\n",
    "    x=str(train_sentences[i])\n",
    "    training_sentences.append(x)\n",
    "    \n",
    "training_sentences=np.array(training_sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_sentences=test1['cleaned_text'].values\n",
    "test_labels=test1['label'].values\n",
    "\n",
    "for i in range(test_sentences.shape[0]): \n",
    "    x=str(test_sentences[i])\n",
    "    testing_sentences.append(x)\n",
    "    \n",
    "testing_sentences=np.array(testing_sentences)\n",
    "\n",
    "\n",
    "train_labels=keras.utils.np_utils.to_categorical(train_labels)\n",
    "\n",
    "\n",
    "test_labels=keras.utils.np_utils.to_categorical(test_labels)\n",
    "print(\"Training Set Length: \"+str(len(train1)))\n",
    "print(\"Testing Set Length: \"+str(len(test1)))\n",
    "print(\"training_sentences shape: \"+str(training_sentences.shape))\n",
    "print(\"testing_sentences shape: \"+str(testing_sentences.shape))\n",
    "print(\"train_labels shape: \"+str(train_labels.shape))\n",
    "print(\"test_labels shape: \"+str(test_labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df43625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¬Ø²Ø§ÙƒÙŠ Ø§Ù„Ù„Ù‡ Ø®ÙŠØ±Ø§\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(training_sentences[10])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a839b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 25000\n",
    "embedding_dim = 300\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c624ae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73476\n",
      "Word index length:73476\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "print(\"Word index length:\"+str(len(tokenizer.word_index)))\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(test_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e1397cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :--> \n",
      "\n",
      "Ø³Ù„Ø§Ù… Ø¹Ù„Ø§ÙƒÙ… âœ‹\n",
      "\n",
      "Sentence Tokenized and Converted into Sequence :--> \n",
      "\n",
      "[758, 24338, 28]\n",
      "\n",
      "After Padding the Sequence with padding length 100 :--> \n",
      "\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0   758 24338    28]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence :--> \\n\")\n",
    "print(training_sentences[6]+\"\\n\")\n",
    "print(\"Sentence Tokenized and Converted into Sequence :--> \\n\")\n",
    "print(str(sequences[6])+\"\\n\")\n",
    "print(\"After Padding the Sequence with padding length 100 :--> \\n\")\n",
    "print(padded[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "774e5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape(training): (29479, 100)\n",
      "Padded shape(testing): (7370, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Padded shape(training): \"+str(padded.shape))\n",
    "print(\"Padded shape(testing): \"+str(testing_padded.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0a48e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          7500000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 8,267,746\n",
      "Trainable params: 8,267,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model1.add(LSTM(256,dropout=0.4, return_sequences=True))\n",
    "model1.add(LSTM(128,dropout=0.5, return_sequences=False))\n",
    "model1.add(Dense(2,activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23804b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "116/116 [==============================] - 181s 2s/step - loss: 0.6220 - accuracy: 0.6384 - val_loss: 0.5594 - val_accuracy: 0.7064\n",
      "Epoch 2/5\n",
      "116/116 [==============================] - 167s 1s/step - loss: 0.4563 - accuracy: 0.7807 - val_loss: 0.5727 - val_accuracy: 0.6984\n",
      "Epoch 3/5\n",
      "116/116 [==============================] - 168s 1s/step - loss: 0.3435 - accuracy: 0.8426 - val_loss: 0.6721 - val_accuracy: 0.6875\n",
      "Epoch 4/5\n",
      "116/116 [==============================] - 168s 1s/step - loss: 0.2507 - accuracy: 0.8909 - val_loss: 0.8139 - val_accuracy: 0.6764\n",
      "Epoch 5/5\n",
      "116/116 [==============================] - 168s 1s/step - loss: 0.1847 - accuracy: 0.9203 - val_loss: 0.9777 - val_accuracy: 0.6704\n"
     ]
    }
   ],
   "source": [
    "history1=model1.fit(padded,train_labels,epochs=5,batch_size=256,validation_data=(testing_padded,test_labels),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc32682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
