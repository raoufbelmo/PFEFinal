{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45deae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aeb648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir('arabic_tweets') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "510169a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a91aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58751 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_data = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'arabic_tweets',\n",
    "    # \"inferred\" : the labels are generated from the directory structure\n",
    "    labels = \"inferred\",\n",
    "    # \"int\": the labels are encoded as integers\n",
    "    label_mode = \"int\",\n",
    "    # Maximum size of a text string. Texts longer than this will be shortened \n",
    "    # to max_length unless it's None ra7at explanation f kil zit.\n",
    "    max_length = None,\n",
    "    # Whether to shuffle the data. If False, sorts the data in alphanumeric order.\n",
    "    shuffle=True,\n",
    "    # Finally haja fahmetha mn bkri\n",
    "    seed=11,\n",
    "    # Optional float between 0 and 1, fraction of data to reserve for validation\n",
    "    validation_split=None,\n",
    "    # Only used if validation_split is set, mahich set alors sotit\n",
    "    subset=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "380cb075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes names:\n",
      " ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes names:\\n\",raw_data.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efd5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58751\n",
      "58751\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for text_batch, label_batch in raw_data:\n",
    "    for i in range(len(text_batch)):\n",
    "        s=text_batch.numpy()[i].decode(\"utf-8\") \n",
    "        x.append(s)\n",
    "        y.append(raw_data.class_names[label_batch.numpy()[i]])\n",
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "685e19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data =pd.DataFrame({\"text\":x,\"label\":y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fd0910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58751, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67479aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is null ? :  \n",
      " ****************  text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58751 entries, 0 to 58750\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    58751 non-null  object\n",
      " 1   label   58751 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 918.1+ KB\n",
      "data info : \n",
      " ****************  None\n",
      "is duplicated : \n",
      " *************  21902\n",
      "data shape \n",
      " :  **************  (58751, 2)\n"
     ]
    }
   ],
   "source": [
    "print('is null ? :  \\n **************** ', data.isnull().sum())\n",
    "print('data info : \\n **************** ', data.info())\n",
    "print('is duplicated : \\n ************* ', data.duplicated().sum())\n",
    "print('data shape \\n :  ************** ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd04575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>سحب على مبلغ مالي 💰 لمتابعي #كشكول 👍🏻 المطلوب:...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>/4/12 - الاتحاد يتوج بطلا للدوري. /4/12 - الات...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>الحمد لله .. كانت مباراه صعبه ولكن بتوفيق الله...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>_⛔ #مناحل_ابو_سلطان . . 🍯 اقسم بالله انه عسل 🍯...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>رئيسين في يومين قالو الربيع العربي 😒 نحنا الكت...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58735</th>\n",
       "      <td>\"تلاتين سنة بترقص .. الليلة رقصتنا\" أنا ببكي 😭...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58739</th>\n",
       "      <td>♥️🌸💞🕊 . 🥀 أرسل تحيه على قدر الغلاء الصافي لأحب...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58744</th>\n",
       "      <td>ٲليس من العيب ان تحفظ كل الأغاني .. وتكرر نفس ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58746</th>\n",
       "      <td>ألطف ما قيل في الإشتياق \"مو ضروري إني أقولك.. ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58749</th>\n",
       "      <td>والله باينه 😎😎 مين شرنوبي ناو😂\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21902 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "66     سحب على مبلغ مالي 💰 لمتابعي #كشكول 👍🏻 المطلوب:...   pos\n",
       "97     /4/12 - الاتحاد يتوج بطلا للدوري. /4/12 - الات...   neg\n",
       "111    الحمد لله .. كانت مباراه صعبه ولكن بتوفيق الله...   pos\n",
       "120    _⛔ #مناحل_ابو_سلطان . . 🍯 اقسم بالله انه عسل 🍯...   neg\n",
       "147    رئيسين في يومين قالو الربيع العربي 😒 نحنا الكت...   neg\n",
       "...                                                  ...   ...\n",
       "58735  \"تلاتين سنة بترقص .. الليلة رقصتنا\" أنا ببكي 😭...   neg\n",
       "58739  ♥️🌸💞🕊 . 🥀 أرسل تحيه على قدر الغلاء الصافي لأحب...   neg\n",
       "58744  ٲليس من العيب ان تحفظ كل الأغاني .. وتكرر نفس ...   neg\n",
       "58746  ألطف ما قيل في الإشتياق \"مو ضروري إني أقولك.. ...   pos\n",
       "58749                   والله باينه 😎😎 مين شرنوبي ناو😂\\n   neg\n",
       "\n",
       "[21902 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5da3442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>والله باينه 😎😎 مين شرنوبي ناو😂\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50898</th>\n",
       "      <td>والله باينه 😎😎 مين شرنوبي ناو😂\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58749</th>\n",
       "      <td>والله باينه 😎😎 مين شرنوبي ناو😂\\n</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text label\n",
       "12279  والله باينه 😎😎 مين شرنوبي ناو😂\\n   neg\n",
       "50898  والله باينه 😎😎 مين شرنوبي ناو😂\\n   neg\n",
       "58749  والله باينه 😎😎 مين شرنوبي ناو😂\\n   neg"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['text']=='والله باينه 😎😎 مين شرنوبي ناو😂\\n'] #fu. for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9e8fcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74ff936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36849, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fece737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['هَاتَيْنِ', 'ذي', 'عجبا', 'غادر', 'هاهنا', 'ماي', 'ز', 'حار', 'آه', 'ميم', 'سبعون', 'ما انفك', 'ى', 'إما', 'كذلك', 'يورو', 'تِي', 'أف', 'هذه', 'شرع', 'خ', 'إنما', 'ألف', 'حاي', 'حيَّ', 'ءَ', 'ر', 'خلا', 'علق', 'واهاً', 'كيف', 'تلقاء', 'نعم', 'إذما', 'رابع', 'تحت', 'ثم', 'أكتوبر', 'أُفٍّ', 'أوه', 'أكثر', 'أبو', 'أيضا', 'نحو', 'لبيك', 'لكي', 'ثمة', 'انبرى', 'عاشر', 'سين', 'شين', 'بكن', 'صدقا', 'وهب', 'بماذا', 'كأيّن', 'اللاتي', 'لنا', 'يوان', 'سرا', 'آناء', 'لو', 'فضلا', 'أفريل', 'واو', 'حيث', 'عدَّ', 'عَدَسْ', 'تحوّل', 'هن', 'إياهما', 'ثلاثاء', 'خاصة', 'وراءَك', 'ذين', 'ياء', 'ع', 'هَيْهات', 'نيسان', 'أوشك', 'فوق', 'ليت', 'مما', 'كرب', 'لا', 'كن', 'أنا', 'بهن', 'أخو', 'آهِ', 'ؤ', 'سقى', 'هلم', 'أربعمئة', 'لكن', 'يفعلان', 'لم', 'اثني', 'صباح', 'إياه', 'هؤلاء', 'رجع', 'ثمانية', 'منها', 'إذن', 'إيانا', 'خمسة', 'نيف', 'طرا', 'تلكما', 'خامس', 'هيت', 'لهما', 'بمن', 'همزة', 'ابتدأ', 'ثمّ', 'جمعة', 'مايو', 'خال', 'شمال', 'ثمَّ', 'سادس', 'ذيت', 'دال', 'استحال', 'أربع', 'جانفي', 'الألاء', 'شَتَّانَ', 'آذار', 'سبعمائة', 'صبرا', 'ثمّة', 'أمامك', 'سرعان', 'أينما', 'مافتئ', 'إياهم', 'ذلكم', 'صبر', 'تعلَّم', 'ج', 'يوليو', 'على', 'ط', 'قبل', 'ومن', 'متى', 'وإن', 'إلّا', 'خمس', 'هذين', 'دينار', 'ستين', 'عيانا', 'لك', 'كليكما', 'هيّا', 'آ', 'ه', 'تارة', 'بغتة', 'أوّهْ', 'تفعلين', 'وإذ', 'هَاتِي', 'هبّ', 'طاء', 'صهٍ', 'تاء', 'شتانَ', 'لها', 'بخ', 'عوض', 'آض', 'تانِ', 'أعلم', 'كأنما', 'ين', 'ما برح', 'س', 'هَذَيْنِ', 'بعد', 'أسكن', 'ساء', 'أصلا', 'إياك', 'حمٌ', 'ليرة', 'جير', 'ها', 'فيفري', 'تلك', 'بَسْ', 'كلاهما', 'بس', 'أقبل', 'سوى', 'أولئك', 'أربعة', 'جلل', 'انقلب', 'أقل', 'كما', 'ذلكما', 'يا', 'أنت', 'تسعمئة', 'علًّ', 'ا', 'فرادى', 'أيّان', 'فلا', 'عدا', 'هيهات', 'ترك', 'بيد', 'اربعون', 'فيه', 'وَيْ', 'خمسين', 'منذ', 'إياكن', 'أمام', 'طالما', 'يونيو', 'إذاً', 'بكم', 'اللذين', 'حبيب', 'أنتم', 'أربعمائة', 'أجمع', 'خمسون', 'جعل', 'لكنما', 'إنَّ', 'اللواتي', 'أهلا', 'بين', 'حتى', 'بضع', 'نَخْ', 'نون', 'غدا', 'ذلك', 'ريث', 'أيها', 'هاكَ', 'إذا', 'أم', 'ب', 'م', 'أخٌ', 'عين', 'بها', 'إلَيْكَ', 'أما', 'اللتان', 'ذِه', 'قلما', 'ذِي', 'إن', 'عسى', 'ذهب', 'هي', 'أبٌ', 'ذاك', 'سوف', 'يفعلون', 'زعم', 'أو', 'آهٍ', 'رُبَّ', 'إي', 'ضحوة', 'سبت', 'واحد', 'إمّا', 'ثلاثمائة', 'ثمانين', 'أولالك', 'غداة', 'أجل', 'ألا', 'ولو', 'بك', 'كل', 'هَذانِ', 'ستة', 'عليك', 'اثنين', 'كاد', 'أفعل به', 'إليكم', 'هكذا', 'راح', 'لعل', 'مساء', 'مئتان', 'غالبا', 'شتان', 'إزاء', 'أربعاء', 'دواليك', 'تي', 'ن', 'عل', 'أطعم', 'ش', 'ليست', 'جنيه', 'آي', 'حسب', 'ذلكن', 'كأين', 'أ', 'وإذا', 'هللة', 'فاء', 'اثنا', 'لسنا', 'عن', 'الألى', 'ذواتا', 'ّأيّان', 'ثلاثين', 'طَق', 'كاف', 'سحقا', 'أوت', 'شباط', 'إيهٍ', 'ليسا', 'هناك', 'لدى', 'حدَث', 'حرى', 'طاق', 'كلما', 'أغسطس', 'تجاه', 'لئن', 'فبراير', 'تينك', 'لن', 'بَلْهَ', 'نبَّا', 'فإن', 'أنتما', 'أحد', 'لما', 'اربعين', 'خلف', 'ذو', 'ثلاثمئة', 'تسع', 'هنا', 'ريال', 'هذان', 'هاء', 'ذال', 'عامة', 'أيّ', 'عليه', 'هَاتانِ', 'راء', 'أخبر', 'إى', 'هَذا', 'صاد', 'الذين', 'لكيلا', 'أمسى', 'جميع', 'وجد', 'تسعمائة', 'فيم', 'كلّما', 'اللتين', 'كأيّ', 'سبعمئة', 'مازال', 'أي', 'كسا', 'شبه', 'أفٍّ', 'وما', 'ة', 'مليم', 'فلس', 'منه', 'رأى', 'آنفا', 'لعلَّ', 'حيثما', 'خمسمائة', 'فو', 'هنالك', 'ثمان', 'باء', 'أمد', 'عشرون', 'من', 'كذا', 'ثاني', 'أين', 'بي', 'لولا', 'تبدّل', 'ذوا', 'لكم', 'كان', 'كيفما', 'غين', 'هيا', 'ظاء', 'تاسع', 'سبحان', 'بطآن', 'ذينك', 'حمو', 'ليستا', 'وُشْكَانَ', 'ص', 'طفق', 'زود', 'ألفى', 'ظنَّ', 'بسّ', 'مذ', 'بعض', 'إياكما', 'ضاد', 'بهم', 'ذا', 'ذَيْنِ', 'آهاً', 'لست', 'ثمانمئة', 'ثان', 'ذه', 'هاتان', 'هذا', 'هذي', 'حقا', 'لستن', 'سمعا', 'ولكن', 'قرش', 'أرى', 'درى', 'كلَّا', 'إليكنّ', 'فمن', 'ء', 'ته', 'تين', 'تِه', 'ما', 'أولاء', 'ذانك', 'حَذارِ', 'جوان', 'ثلاث', 'إذ', 'ف', 'أنتن', 'نوفمبر', 'تَيْنِ', 'ثالث', 'كلتا', 'ثلاثون', 'تسعين', 'ذات', 'كانون', 'شيكل', 'سبتمبر', 'اخلولق', 'يناير', 'كِخ', 'تخذ', 'صراحة', 'مادام', 'لمّا', 'أعطى', 'لستم', 'إليكما', 'تموز', 'أنتِ', 'لوما', 'قاف', 'بما', 'كأنّ', 'ث', 'إليك', 'تعسا', 'إليكن', 'حاشا', 'خبَّر', 'أنبأ', 'ست', 'ثامن', 'ض', 'عند', 'أمّا', 'هما', 'أمس', 'خلافا', 'كم', 'إحدى', 'بل', 'ثاء', 'في', 'حادي', 'نفس', 'هاته', 'إنا', 'ظ', 'ما أفعله', 'سبعين', 'سابع', 'ثماني', 'صهْ', 'وا', 'ستمئة', 'إياكم', 'دون', 'اللائي', 'رزق', 'هَذِي', 'رويدك', 'هَجْ', 'الذي', 'عشرين', 'ق', 'بؤسا', 'بنا', 'عما', 'تفعلون', 'ارتدّ', 'تسعة', 'نا', 'لهم', 'ل', 'مه', 'كيت', 'هم', 'د', 'ك', 'معاذ', 'ليس', 'مكانكم', 'أخذ', 'حمدا', 'لعمر', 'حبذا', 'ظلّ', 'لاسيما', 'عاد', 'هل', 'أيلول', 'ت', 'نَّ', 'عشر', 'تانِك', 'ذواتي', 'تفعلان', 'أبدا', 'خاء', 'بات', 'اللذان', 'سبع', 'اتخذ', 'حاء', 'مائة', 'ثمنمئة', 'هلا', 'ثمانون', 'كثيرا', 'قطّ', 'به', 'أول', 'مع', 'إياهن', 'بعدا', 'أيا', 'لكنَّ', 'علم', 'جويلية', 'والذين', 'لكما', 'إلا', 'بلى', 'حزيران', 'مارس', 'اثنان', 'مكانكما', 'كليهما', 'جيم', 'هَاتِه', 'زاي', 'إنه', 'وهو', 'ستمائة', 'إلى', 'مثل', 'إليكَ', 'أنى', 'فيها', 'دونك', 'سبعة', 'تلكم', 'غ', 'قد', 'ليسوا', 'آمينَ', 'أبريل', 'و', 'هَؤلاء', 'خميس', 'مهما', 'كلا', 'فإذا', 'ح', 'بكما', 'مكانكنّ', 'أصبح', 'أنًّ', 'أضحى', 'قام', 'كي', 'اللتيا', 'مكانَك', 'ذان', 'خمسمئة', 'أى', 'لا سيما', 'تسعون', 'درهم', 'بهما', 'غير', 'له', 'هلّا', 'ئ', 'هو', 'آها', 'كأن', 'لام', 'لي', 'ديسمبر', 'بخٍ', 'لدن', 'هاك', 'آب', 'تشرين', 'حجا', 'فلان', 'هاتي', 'دولار', 'أن', 'صار', 'ي', 'ماذا', 'لهن', 'لستما', 'ممن', 'أيار', 'أنّى', 'ذ', 'إيه', 'فيما', 'إياها', 'إياي', 'التي', 'كى', 'ستون', 'سنتيم', 'ورد', 'أل', 'هاتين', 'ذانِ', 'عشرة', 'ثلاثة', 'كأي', 'لات', 'ولا', 'حين', 'مئة', 'لسن', 'الآن', 'يمين', 'أمامكَ', 'قاطبة', 'والذي', 'مرّة', 'نحن', 'هَذِه', 'بئس', 'أنشأ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ethernet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = list(set(stopwords.words('arabic')))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a77ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f586265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(arabic_diacritics, '', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_diacritics(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word for word in tokens if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d89ed662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.. امنيھ مسائيھ : 🌿 ربي أكتب لنآ سعادھ دائمھ 🌱...</td>\n",
       "      <td>pos</td>\n",
       "      <td>امنيھ مسائيھ ربي أكتب لنآ سعادھ دائمھ وأبتسامھ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>النصر للنصر باذن الله 💛 #الاتحاد_النصر حال الط...</td>\n",
       "      <td>pos</td>\n",
       "      <td>النصر للنصر باذن الله الاتحادالنصر حال الطواقي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لا تعلم أي الأعمال التي ستقر بها عينك في دنياك...</td>\n",
       "      <td>pos</td>\n",
       "      <td>تعلم الأعمال ستقر عينك دنياك وأخراك، تحيل قابل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بحول الله فوز يسر قلوب العاشقيين 💛 ويغيض كبوود...</td>\n",
       "      <td>pos</td>\n",
       "      <td>بحول الله فوز يسر قلوب العاشقيين ويغيض كبوود ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>صباح الخير // واقصد بالخير حبيبي :(\\n</td>\n",
       "      <td>neg</td>\n",
       "      <td>الخير واقصد بالخير حبيبي</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  \\\n",
       "0  .. امنيھ مسائيھ : 🌿 ربي أكتب لنآ سعادھ دائمھ 🌱...   pos   \n",
       "1  النصر للنصر باذن الله 💛 #الاتحاد_النصر حال الط...   pos   \n",
       "2  لا تعلم أي الأعمال التي ستقر بها عينك في دنياك...   pos   \n",
       "3  بحول الله فوز يسر قلوب العاشقيين 💛 ويغيض كبوود...   pos   \n",
       "4              صباح الخير // واقصد بالخير حبيبي :(\\n   neg   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  امنيھ مسائيھ ربي أكتب لنآ سعادھ دائمھ وأبتسامھ...  \n",
       "1  النصر للنصر باذن الله الاتحادالنصر حال الطواقي...  \n",
       "2  تعلم الأعمال ستقر عينك دنياك وأخراك، تحيل قابل...  \n",
       "3  بحول الله فوز يسر قلوب العاشقيين ويغيض كبوود ا...  \n",
       "4                           الخير واقصد بالخير حبيبي  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b538712a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.. امنيھ مسائيھ : 🌿 ربي أكتب لنآ سعادھ دائمھ 🌱...</td>\n",
       "      <td>1</td>\n",
       "      <td>امنيھ مسائيھ ربي أكتب لنآ سعادھ دائمھ وأبتسامھ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>النصر للنصر باذن الله 💛 #الاتحاد_النصر حال الط...</td>\n",
       "      <td>1</td>\n",
       "      <td>النصر للنصر باذن الله الاتحادالنصر حال الطواقي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لا تعلم أي الأعمال التي ستقر بها عينك في دنياك...</td>\n",
       "      <td>1</td>\n",
       "      <td>تعلم الأعمال ستقر عينك دنياك وأخراك، تحيل قابل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بحول الله فوز يسر قلوب العاشقيين 💛 ويغيض كبوود...</td>\n",
       "      <td>1</td>\n",
       "      <td>بحول الله فوز يسر قلوب العاشقيين ويغيض كبوود ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>صباح الخير // واقصد بالخير حبيبي :(\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>الخير واقصد بالخير حبيبي</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  .. امنيھ مسائيھ : 🌿 ربي أكتب لنآ سعادھ دائمھ 🌱...      1   \n",
       "1  النصر للنصر باذن الله 💛 #الاتحاد_النصر حال الط...      1   \n",
       "2  لا تعلم أي الأعمال التي ستقر بها عينك في دنياك...      1   \n",
       "3  بحول الله فوز يسر قلوب العاشقيين 💛 ويغيض كبوود...      1   \n",
       "4              صباح الخير // واقصد بالخير حبيبي :(\\n      0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  امنيھ مسائيھ ربي أكتب لنآ سعادھ دائمھ وأبتسامھ...  \n",
       "1  النصر للنصر باذن الله الاتحادالنصر حال الطواقي...  \n",
       "2  تعلم الأعمال ستقر عينك دنياك وأخراك، تحيل قابل...  \n",
       "3  بحول الله فوز يسر قلوب العاشقيين ويغيض كبوود ا...  \n",
       "4                           الخير واقصد بالخير حبيبي  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert positive 1 and negative 0\n",
    "data['label']=data['label'].apply(lambda X: 0 if X == 'neg' else 1 )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d39ead40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from time import time \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Activation,Embedding,Flatten,Bidirectional,MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import h5py\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89ceaac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Length: 29479\n",
      "Testing Set Length: 7370\n",
      "training_sentences shape: (29479,)\n",
      "testing_sentences shape: (7370,)\n",
      "train_labels shape: (29479, 2)\n",
      "test_labels shape: (7370, 2)\n"
     ]
    }
   ],
   "source": [
    "train1, test1 = train_test_split(data,random_state=69, test_size=0.2)\n",
    "training_sentences = []\n",
    "testing_sentences = []\n",
    "\n",
    "\n",
    "\n",
    "train_sentences=train1['cleaned_text'].values\n",
    "train_labels=train1['label'].values\n",
    "for i in range(train_sentences.shape[0]): \n",
    "    #print(train_sentences[i])\n",
    "    x=str(train_sentences[i])\n",
    "    training_sentences.append(x)\n",
    "    \n",
    "training_sentences=np.array(training_sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_sentences=test1['cleaned_text'].values\n",
    "test_labels=test1['label'].values\n",
    "\n",
    "for i in range(test_sentences.shape[0]): \n",
    "    x=str(test_sentences[i])\n",
    "    testing_sentences.append(x)\n",
    "    \n",
    "testing_sentences=np.array(testing_sentences)\n",
    "\n",
    "\n",
    "train_labels=keras.utils.np_utils.to_categorical(train_labels)\n",
    "\n",
    "\n",
    "test_labels=keras.utils.np_utils.to_categorical(test_labels)\n",
    "print(\"Training Set Length: \"+str(len(train1)))\n",
    "print(\"Testing Set Length: \"+str(len(test1)))\n",
    "print(\"training_sentences shape: \"+str(training_sentences.shape))\n",
    "print(\"testing_sentences shape: \"+str(testing_sentences.shape))\n",
    "print(\"train_labels shape: \"+str(train_labels.shape))\n",
    "print(\"test_labels shape: \"+str(test_labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df43625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جزاكي الله خيرا\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(training_sentences[10])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a839b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 25000\n",
    "embedding_dim = 300\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c624ae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73476\n",
      "Word index length:73476\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "print(\"Word index length:\"+str(len(tokenizer.word_index)))\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(test_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e1397cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :--> \n",
      "\n",
      "سلام علاكم ✋\n",
      "\n",
      "Sentence Tokenized and Converted into Sequence :--> \n",
      "\n",
      "[758, 24338, 28]\n",
      "\n",
      "After Padding the Sequence with padding length 100 :--> \n",
      "\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0   758 24338    28]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence :--> \\n\")\n",
    "print(training_sentences[6]+\"\\n\")\n",
    "print(\"Sentence Tokenized and Converted into Sequence :--> \\n\")\n",
    "print(str(sequences[6])+\"\\n\")\n",
    "print(\"After Padding the Sequence with padding length 100 :--> \\n\")\n",
    "print(padded[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "774e5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape(training): (29479, 100)\n",
      "Padded shape(testing): (7370, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Padded shape(training): \"+str(padded.shape))\n",
    "print(\"Padded shape(testing): \"+str(testing_padded.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0a48e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          7500000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 8,267,746\n",
      "Trainable params: 8,267,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model1.add(LSTM(256,dropout=0.4, return_sequences=True))\n",
    "model1.add(LSTM(128,dropout=0.5, return_sequences=False))\n",
    "model1.add(Dense(2,activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23804b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "116/116 [==============================] - 181s 2s/step - loss: 0.6220 - accuracy: 0.6384 - val_loss: 0.5594 - val_accuracy: 0.7064\n",
      "Epoch 2/5\n",
      "116/116 [==============================] - 167s 1s/step - loss: 0.4563 - accuracy: 0.7807 - val_loss: 0.5727 - val_accuracy: 0.6984\n",
      "Epoch 3/5\n",
      "116/116 [==============================] - 168s 1s/step - loss: 0.3435 - accuracy: 0.8426 - val_loss: 0.6721 - val_accuracy: 0.6875\n",
      "Epoch 4/5\n",
      "116/116 [==============================] - 168s 1s/step - loss: 0.2507 - accuracy: 0.8909 - val_loss: 0.8139 - val_accuracy: 0.6764\n",
      "Epoch 5/5\n",
      "116/116 [==============================] - 168s 1s/step - loss: 0.1847 - accuracy: 0.9203 - val_loss: 0.9777 - val_accuracy: 0.6704\n"
     ]
    }
   ],
   "source": [
    "history1=model1.fit(padded,train_labels,epochs=5,batch_size=256,validation_data=(testing_padded,test_labels),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc32682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
