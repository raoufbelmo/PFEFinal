{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f8028cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from time import time \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Dropout,Activation,Embedding,Flatten,Bidirectional,MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import h5py\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "74d899ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def replace_strings(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\u00C0-\\u017F\"          #latin\n",
    "                           u\"\\u2000-\\u206F\"          #generalPunctuations\n",
    "                               \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    english_pattern=re.compile('[a-zA-Z0-9]+', flags=re.I)\n",
    "    #latin_pattern=re.compile('[A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00f6\\u00f8-\\u00ff\\s]*',)\n",
    "    \n",
    "    text=emoji_pattern.sub(r'', text)\n",
    "    text=english_pattern.sub(r'', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(my_str):\n",
    "    # define punctuation\n",
    "    punctuations = '''```\u0012\u0010\u0002\b`\u0007\b¬£|¬¢|\u0007√ë+-*/=EROero‡ß≥‡ß¶‡ßß‡ß®‡ß©‡ß™‡ß´‡ß¨‡ß≠‡ßÆ‡ßØ012‚Äì34567‚Ä¢89‡•§!()-[]{};:'\"‚Äú\\‚Äô,<>./?@#$%^&*_~‚Äò‚Äî‡••‚Äù‚Ä∞‚öΩÔ∏è‚úåÔøΩÔø∞‡ß∑Ôø∞'''\n",
    "    \n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "\n",
    "def joining(text):\n",
    "    out=' '.join(text)\n",
    "    return out\n",
    "\n",
    "def preprocessing(text):\n",
    "    out=remove_punctuations(replace_strings(text))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d7eeb412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Tweets2.csv')\n",
    "df = df[[\"airline_sentiment\",\"text\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8dded2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>2</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>2</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0                     2                @VirginAmerica What @dhepburn said.\n",
       "1                     1  @VirginAmerica plus you've added commercials t...\n",
       "2                     2  @VirginAmerica I didn't today... Must mean I n...\n",
       "3                     0  @VirginAmerica it's really aggressive to blast...\n",
       "4                     0  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635                 1  @AmericanAir thank you we got on a different f...\n",
       "14636                 0  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637                 2  @AmericanAir Please bring American Airlines to...\n",
       "14638                 0  @AmericanAir you have my money, you change my ...\n",
       "14639                 2  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment\"] = df[\"airline_sentiment\"].replace(regex=\"neutral\", value=2)\n",
    "df[\"airline_sentiment\"] = df[\"airline_sentiment\"].replace(regex=\"positive\", value=1)\n",
    "df[\"airline_sentiment\"] = df[\"airline_sentiment\"].replace(regex=\"negative\", value=0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cddb8f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir right on cue with the delaysüëå</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11541 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "1                     1  @VirginAmerica plus you've added commercials t...\n",
       "3                     0  @VirginAmerica it's really aggressive to blast...\n",
       "4                     0  @VirginAmerica and it's a really big bad thing...\n",
       "5                     0  @VirginAmerica seriously would pay $30 a fligh...\n",
       "6                     1  @VirginAmerica yes, nearly every time I fly VX...\n",
       "...                 ...                                                ...\n",
       "14633                 0  @AmericanAir my flight was Cancelled Flightled...\n",
       "14634                 0         @AmericanAir right on cue with the delaysüëå\n",
       "14635                 1  @AmericanAir thank you we got on a different f...\n",
       "14636                 0  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14638                 0  @AmericanAir you have my money, you change my ...\n",
       "\n",
       "[11541 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.index[df['airline_sentiment'] == 2], inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1c6c3fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Length: 9232\n",
      "Testing Set Length: 2309\n",
      "training_sentences shape: (9232,)\n",
      "testing_sentences shape: (2309,)\n",
      "train_labels shape: (9232, 2)\n",
      "test_labels shape: (2309, 2)\n"
     ]
    }
   ],
   "source": [
    "train1, test1 = train_test_split(df,random_state=69, test_size=0.2)\n",
    "training_sentences = []\n",
    "testing_sentences = []\n",
    "\n",
    "\n",
    "\n",
    "train_sentences=train1['text'].values\n",
    "train_labels=train1['airline_sentiment'].values\n",
    "for i in range(train_sentences.shape[0]): \n",
    "    #print(train_sentences[i])\n",
    "    x=str(train_sentences[i])\n",
    "    training_sentences.append(x)\n",
    "    \n",
    "training_sentences=np.array(training_sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_sentences=test1['text'].values\n",
    "test_labels=test1['airline_sentiment'].values\n",
    "\n",
    "for i in range(test_sentences.shape[0]): \n",
    "    x=str(test_sentences[i])\n",
    "    testing_sentences.append(x)\n",
    "    \n",
    "testing_sentences=np.array(testing_sentences)\n",
    "\n",
    "\n",
    "train_labels=keras.utils.np_utils.to_categorical(train_labels)\n",
    "\n",
    "\n",
    "test_labels=keras.utils.np_utils.to_categorical(test_labels)\n",
    "print(\"Training Set Length: \"+str(len(train1)))\n",
    "print(\"Testing Set Length: \"+str(len(test1)))\n",
    "print(\"training_sentences shape: \"+str(training_sentences.shape))\n",
    "print(\"testing_sentences shape: \"+str(testing_sentences.shape))\n",
    "print(\"train_labels shape: \"+str(train_labels.shape))\n",
    "print(\"test_labels shape: \"+str(test_labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2cdf5c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USAirways is the worst. 45 minute delay in Boston. Not weather reLate Flightd. Going to miss our connecting flight. Gassing up the plane issue.\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(training_sentences[6])\n",
    "print(train_labels[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c8c1f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 25000\n",
    "embedding_dim = 300\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b64358c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11600\n",
      "Word index length:11600\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "print(\"Word index length:\"+str(len(tokenizer.word_index)))\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(test_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "154089b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :--> \n",
      "\n",
      "@USAirways is the worst. 45 minute delay in Boston. Not weather reLate Flightd. Going to miss our connecting flight. Gassing up the plane issue.\n",
      "\n",
      "Sentence Tokenized and Converted into Sequence :--> \n",
      "\n",
      "[13, 15, 3, 149, 361, 523, 122, 16, 435, 23, 146, 1167, 934, 127, 2, 225, 69, 393, 9, 5020, 51, 3, 60, 238]\n",
      "\n",
      "After Padding the Sequence with padding length 100 :--> \n",
      "\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0   13   15    3  149  361  523  122   16\n",
      "  435   23  146 1167  934  127    2  225   69  393    9 5020   51    3\n",
      "   60  238]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence :--> \\n\")\n",
    "print(training_sentences[6]+\"\\n\")\n",
    "print(\"Sentence Tokenized and Converted into Sequence :--> \\n\")\n",
    "print(str(sequences[6])+\"\\n\")\n",
    "print(\"After Padding the Sequence with padding length 100 :--> \\n\")\n",
    "print(padded[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fab7ce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded shape(training): (9232, 100)\n",
      "Padded shape(testing): (2309, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Padded shape(training): \"+str(padded.shape))\n",
    "print(\"Padded shape(testing): \"+str(testing_padded.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8847bd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          7500000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 200)           180200    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 98, 128)           135680    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 7,928,998\n",
      "Trainable params: 7,928,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model= Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "    model.add(Conv1D(200, kernel_size=3, activation = \"relu\"))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(64)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    #l2 regularizer\n",
    "    model.add(Dense(100,kernel_regularizer=regularizers.l2(0.01),activation=\"relu\"))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    #sgd= SGD(lr=0.0001,decay=1e-6,momentum=0.9,nesterov=True)\n",
    "    adam=Adam(learning_rate=0.0005,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c39b5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37/37 [==============================] - 41s 877ms/step - loss: 1.1084 - accuracy: 0.7777 - val_loss: 0.8896 - val_accuracy: 0.8129\n",
      "Epoch 2/5\n",
      "37/37 [==============================] - 32s 857ms/step - loss: 0.7410 - accuracy: 0.8750 - val_loss: 0.6250 - val_accuracy: 0.9147\n",
      "Epoch 3/5\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4884 - accuracy: 0.9493 - val_loss: 0.5207 - val_accuracy: 0.9264\n",
      "Epoch 4/5\n",
      "37/37 [==============================] - 35s 943ms/step - loss: 0.3444 - accuracy: 0.9754 - val_loss: 0.4514 - val_accuracy: 0.9181\n",
      "Epoch 5/5\n",
      "37/37 [==============================] - 34s 917ms/step - loss: 0.2486 - accuracy: 0.9882 - val_loss: 0.4063 - val_accuracy: 0.9290\n"
     ]
    }
   ],
   "source": [
    "    history=model.fit(padded,train_labels,epochs=5,batch_size=256,validation_data=(testing_padded,test_labels),use_multiprocessing=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800e28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
